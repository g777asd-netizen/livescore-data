import requests
import json
from datetime import datetime

def scrape_auto_live():
    # Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¯ÙˆØ±ÙŠØ§Øª
    leagues = [
        {"name": "EPL", "url": "eng.1"},       # Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠ
        {"name": "La Liga", "url": "esp.1"},   # Ø¥Ø³Ø¨Ø§Ù†ÙŠ
        {"name": "Bundesliga", "url": "ger.1"},# Ø£Ù„Ù…Ø§Ù†ÙŠ
        {"name": "Serie A", "url": "ita.1"},   # Ø¥ÙŠØ·Ø§Ù„ÙŠ
        {"name": "Ligue 1", "url": "fra.1"},   # ÙØ±Ù†Ø³ÙŠ
        {"name": "UCL", "url": "uefa.champions"}, # Ø£Ø¨Ø·Ø§Ù„ Ø£ÙˆØ±ÙˆØ¨Ø§
        {"name": "CAF CL", "url": "caf.champions"}, # Ø£Ø¨Ø·Ø§Ù„ Ø£ÙØ±ÙŠÙ‚ÙŠØ§
        {"name": "KSA League", "url": "sau.1"}, # Ø§Ù„Ø¯ÙˆØ±ÙŠ Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠ
        {"name": "EGY League", "url": "egy.1"}   # Ø§Ù„Ø¯ÙˆØ±ÙŠ Ø§Ù„Ù…ØµØ±ÙŠ
    ]
    
    print("ğŸš€ Ø¬Ø§Ø±ÙŠ Ø³Ø­Ø¨ Ø§Ù„Ù…Ø¨Ø§Ø±ÙŠØ§Øª Ø§Ù„Ø­Ø§Ù„ÙŠØ© (ØªØ¬Ø§Ù‡Ù„ Ø§Ù„ØªØ§Ø±ÙŠØ®)...")
    
    all_matches = []
    current_display_date = datetime.now().strftime("%Y-%m-%d") # Ù„Ù„ØªØ³Ø¬ÙŠÙ„ ÙÙ‚Ø·

    for league in leagues:
        # !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
        # Ø§Ù„ØªØºÙŠÙŠØ± Ø§Ù„Ø¬ÙˆÙ‡Ø±ÙŠ: Ø­Ø°ÙÙ†Ø§ Ø¬Ø²Ø¡ (?dates=...)
        # Ù‡Ø°Ø§ ÙŠØ¬Ø¨Ø± Ø§Ù„Ù…ÙˆÙ‚Ø¹ Ø¹Ù„Ù‰ Ø¥Ø±Ø³Ø§Ù„ Ù…Ø¨Ø§Ø±ÙŠØ§Øª "Ø§Ù„ÙŠÙˆÙ…" Ø§Ù„Ø­Ø§Ù„ÙŠØ©
        # !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
        url = f"https://site.api.espn.com/apis/site/v2/sports/soccer/{league['url']}/scoreboard"
        
        headers = {'User-Agent': 'Mozilla/5.0'}

        try:
            response = requests.get(url, headers=headers, timeout=10)
            if response.status_code == 200:
                data = response.json()
                events = data.get('events', [])
                
                # Ø·Ø¨Ø§Ø¹Ø© Ù„Ù„ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø¨ÙŠØ§Ù†Ø§Øª
                if len(events) > 0:
                    print(f"   âœ… ÙˆØ¬Ø¯Ù†Ø§ {len(events)} Ù…Ø¨Ø§Ø±Ø§Ø© ÙÙŠ {league['name']}")

                for event in events:
                    competitions = event.get('competitions', [{}])[0]
                    competitors = competitions.get('competitions', [])
                    
                    home = next((t for t in competitors if t['homeAway'] == 'home'), None)
                    away = next((t for t in competitors if t['homeAway'] == 'away'), None)
                    
                    if home and away:
                        status = event.get('status', {}).get('type', {})
                        match_status = status.get('shortDetail', '')
                        state = status.get('state', '') # pre, in, post
                        is_live = (state == 'in')
                        
                        # Ù†Ø³ØªØ®Ø¯Ù… Ø§Ù„ØªØ§Ø±ÙŠØ® Ø§Ù„Ù‚Ø§Ø¯Ù… Ù…Ù† Ø§Ù„Ù…Ø¨Ø§Ø±Ø§Ø© Ù†ÙØ³Ù‡Ø§ Ù„Ø¶Ù…Ø§Ù† Ø§Ù„Ø¯Ù‚Ø©
                        match_date = event.get('date', '')[:10] # 2026-02-28
                        
                        all_matches.append({
                            "league": league['name'],
                            "date": match_date, # ØªØ§Ø±ÙŠØ® Ø§Ù„Ù…Ø¨Ø§Ø±Ø§Ø© Ø§Ù„ÙØ¹Ù„ÙŠ Ù…Ù† Ø§Ù„Ù…ØµØ¯Ø±
                            "home": home['team']['name'],
                            "away": away['team']['name'],
                            "home_score": home.get('score', '0'),
                            "away_score": away.get('score', '0'),
                            "home_logo": home['team'].get('logo', ''),
                            "away_logo": away['team'].get('logo', ''),
                            "status": match_status,
                            "live": is_live
                        })
        except Exception as e:
            print(f"âš ï¸ Ø®Ø·Ø£ ÙÙŠ {league['name']}: {e}")
            continue

    print(f"ğŸ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©: {len(all_matches)} Ù…Ø¨Ø§Ø±Ø§Ø©.")
    
    # Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù
    with open('matches.json', 'w', encoding='utf-8') as f:
        json.dump(all_matches, f, ensure_ascii=False, indent=2)

if __name__ == "__main__":
    scrape_auto_live()
